# ISS-0004: Critical Memory Optimization - Session Impact and Performance Degradation

## Status: open
## Priority: P0 (Critical)
## Epic: EP-0046-framework-optimizations
## Created: 2025-07-22
## Assignee: Framework Team

## Problem Statement

Memory issues are becoming increasingly noticeable and now regularly impacting Claude PM Framework sessions. Users are experiencing performance degradation and potential session failures due to memory accumulation patterns across multiple framework components.

## Root Causes Identified

### 1. SharedPromptCache Memory Accumulation
- Unbounded growth in OrderedDict cache
- 30-minute TTL is too long for active sessions
- Cache cleanup runs every 5 minutes (insufficient)
- No memory pressure-based eviction

### 2. Multiple Singleton Services Without Cleanup
- 7+ singleton instances accumulate state indefinitely
- Missing coordinated cleanup mechanisms
- No global memory pressure response

### 3. Node.js Wrapper Memory Exhaustion (ISS-0109)
- 8GB heap exhaustion in ~6.5 minutes
- Global caches growing unbounded
- Subprocess memory arrays without limits

### 4. Agent Loading Pattern Issues
- 1-hour TTL on agent prompt caches
- Multiple uncoordinated cache layers
- Complex task analysis memory overhead

### 5. Subprocess Memory Management
- High memory thresholds (1GB warning, 2GB critical)
- No aggregate memory pressure handling
- Missing proactive cleanup

## Impact

- Session performance degradation over time
- Potential session crashes due to memory exhaustion
- User productivity impact
- Framework reliability concerns

## Proposed Solution

### Phase 1: Immediate Fixes (Week 1)

1. **Fix SharedPromptCache**
   - Reduce TTL from 30 minutes to 5 minutes
   - Implement memory-based eviction
   - Add aggressive cleanup on memory pressure
   - Add cache metrics to health monitoring

2. **Implement Memory Pressure Response**
   - Global memory monitor service
   - Coordinated cleanup across all services
   - Dynamic cache size adjustment
   - Early warning system

3. **Subprocess Memory Management**
   - Lower thresholds (500MB warning, 1GB critical)
   - Implement subprocess timeout/cleanup
   - Track aggregate subprocess memory

### Phase 2: Systematic Improvements (Week 2)

4. **Service Lifecycle Management**
   - Implement proper cleanup for all singletons
   - Add periodic cleanup tasks
   - Memory leak detection in health checks
   - Graceful shutdown procedures

5. **Context Management Optimization**
   - Streaming for large prompt generation
   - Context size limits and truncation
   - Use generators instead of large lists
   - Implement chunking for large operations

6. **Monitoring and Diagnostics**
   - Memory profiling endpoints
   - Real-time memory usage tracking
   - Memory leak detection tools
   - Performance benchmarking suite

## Implementation Tasks

### Immediate (P0)
- [ ] Reduce SharedPromptCache TTL to 5 minutes
- [ ] Implement memory-based cache eviction
- [ ] Add global memory pressure monitor
- [ ] Lower subprocess memory thresholds
- [ ] Add emergency memory cleanup command

### Short-term (P1)
- [ ] Implement service cleanup coordination
- [ ] Add memory leak detection to health checks
- [ ] Create memory profiling endpoints
- [ ] Implement context streaming/chunking
- [ ] Add memory usage to monitoring dashboard

### Medium-term (P2)
- [ ] Refactor singleton patterns for better lifecycle management
- [ ] Implement comprehensive memory benchmarking
- [ ] Create automated memory regression tests
- [ ] Document memory optimization best practices

## Success Criteria

1. **Performance**: Sessions maintain consistent performance over 8+ hours
2. **Memory Usage**: Peak memory usage reduced by 50%
3. **Stability**: Zero memory-related crashes in 7-day period
4. **Monitoring**: Real-time visibility into memory usage patterns
5. **Recovery**: Ability to recover from high memory situations

## Testing Requirements

1. **Memory Profiling**
   - Before/after memory usage comparison
   - Long-running session tests (8+ hours)
   - Concurrent session stress tests

2. **Performance Benchmarks**
   - Response time consistency over time
   - Cache hit/miss ratios
   - Cleanup efficiency metrics

3. **Regression Tests**
   - Automated memory leak detection
   - Peak memory usage tracking
   - Session stability validation

## Learning Capture

### Key Insights
1. Multiple cache layers without coordination lead to memory bloat
2. Long TTLs (30-60 minutes) are inappropriate for active sessions
3. Singleton patterns need explicit lifecycle management
4. Memory pressure requires system-wide coordinated response
5. Subprocess memory must be tracked in aggregate

### Best Practices
1. Use bounded collections with size limits
2. Implement memory-based eviction, not just count-based
3. Shorter TTLs for frequently accessed data
4. Weakref for memory-sensitive references
5. Streaming/chunking for large data operations

### Architecture Improvements
1. Global memory pressure event system
2. Coordinated service cleanup framework
3. Hierarchical cache management
4. Subprocess lifecycle management
5. Real-time memory monitoring infrastructure

## References

- ISS-0109: Node.js memory leak (8GB heap exhaustion)
- SharedPromptCache implementation analysis
- Singleton service inventory and cleanup patterns
- Agent loading and caching mechanisms

## Notes

This is a critical issue affecting user productivity and framework reliability. The phased approach allows for immediate relief while building toward a comprehensive solution. Focus should be on quick wins in Phase 1 while planning for systematic improvements in Phase 2.